{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d77b7565-4758-48ac-b8d2-a39a61602def",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 17:05:46.567830: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-12 17:05:46.608793: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-12 17:05:46.917083: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-12 17:05:46.919044: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-12 17:05:47.896966: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from glob import glob\n",
    "from tensorflow.keras.layers import Input, Dense, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras import backend as K\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fbbd9ae-6355-48f3-9b65-19a1b226f7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(path, width, height):\n",
    "    img = Image.open(path)\n",
    "    new_image = img.resize((width, height))\n",
    "    new_image = np.array(new_image)\n",
    "    if new_image.shape[2] > 3:\n",
    "        print(f\"No rgb image detected: {path}\")\n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "524dfca0-6ef2-4bf1-b536-4a341baa11fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = glob(\"images/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b479d546-cd13-4e90-830b-ff0866780ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 500\n",
    "width = 500\n",
    "x_train = []\n",
    "for path in paths:\n",
    "    x_train.append(resize(path, height, width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b010a1a-080f-4fd7-bf99-7bf198a345c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for image in x_train:\n",
    "#     print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e937bad4-b978-4ce5-801b-680cb7a5d6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b39157bb-36cb-4249-89f3-dafbfe88d329",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples, _, _, n_bands = x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e33997fa-53ac-45ff-bf60-b02168f70d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(n_samples, height*width*n_bands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "173f0709-67bb-4f3e-adc0-66b1d6fc6fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparametersx_t\n",
    "latent_dim = 3  # Dimensionality of the latent space\n",
    "input_dim = height * width * n_bands  # Input dimension (e.g., flattened MNIST images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68c4f380-a242-4e81-88df-7857d53e9a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 17:06:24.040660: W tensorflow/tsl/framework/bfc_allocator.cc:485] Allocator (mklcpu) ran out of memory trying to allocate 5.72GiB (rounded to 6144000000)requested by op Mul\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2024-12-12 17:06:24.041197: I tensorflow/tsl/framework/bfc_allocator.cc:1039] BFCAllocator dump for mklcpu\n",
      "2024-12-12 17:06:24.041221: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (256): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-12-12 17:06:24.041233: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (512): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-12-12 17:06:24.041244: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (1024): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-12-12 17:06:24.041254: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (2048): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-12-12 17:06:24.041280: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-12-12 17:06:24.041290: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-12-12 17:06:24.041300: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-12-12 17:06:24.041310: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-12-12 17:06:24.041320: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (65536): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-12-12 17:06:24.041330: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-12-12 17:06:24.041340: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-12-12 17:06:24.041350: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-12-12 17:06:24.041360: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-12-12 17:06:24.041370: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-12-12 17:06:24.041380: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-12-12 17:06:24.041391: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-12-12 17:06:24.041401: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-12-12 17:06:24.041411: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-12-12 17:06:24.041422: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-12-12 17:06:24.041432: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-12-12 17:06:24.041499: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (268435456): \tTotal Chunks: 2, Chunks in use: 1. 7.32GiB allocated for chunks. 5.72GiB in use in bin. 5.72GiB client-requested in use in bin.\n",
      "2024-12-12 17:06:24.041527: I tensorflow/tsl/framework/bfc_allocator.cc:1062] Bin for 5.72GiB was 256.00MiB, Chunk State: \n",
      "2024-12-12 17:06:24.041542: I tensorflow/tsl/framework/bfc_allocator.cc:1068]   Size: 1.60GiB | Requested Size: 0B | in_use: 0 | bin_num: 20, prev:   Size: 5.72GiB | Requested Size: 5.72GiB | in_use: 1 | bin_num: -1\n",
      "2024-12-12 17:06:24.041552: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 7861817344\n",
      "2024-12-12 17:06:24.041562: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 742377600040 of size 6144000000 next 1\n",
      "2024-12-12 17:06:24.041571: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7424e5960040 of size 1717817344 next 18446744073709551615\n",
      "2024-12-12 17:06:24.041579: I tensorflow/tsl/framework/bfc_allocator.cc:1100]      Summary of in-use Chunks by size: \n",
      "2024-12-12 17:06:24.041589: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 6144000000 totalling 5.72GiB\n",
      "2024-12-12 17:06:24.041599: I tensorflow/tsl/framework/bfc_allocator.cc:1107] Sum Total of in-use chunks: 5.72GiB\n",
      "2024-12-12 17:06:24.041608: I tensorflow/tsl/framework/bfc_allocator.cc:1109] Total bytes in pool: 7861817344 memory_limit_: 7861817344 available bytes: 0 curr_region_allocation_bytes_: 8589934592\n",
      "2024-12-12 17:06:24.041626: I tensorflow/tsl/framework/bfc_allocator.cc:1114] Stats: \n",
      "Limit:                      7861817344\n",
      "InUse:                      6144000000\n",
      "MaxInUse:                   6144000000\n",
      "NumAllocs:                           1\n",
      "MaxAllocSize:               6144000000\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2024-12-12 17:06:24.041638: W tensorflow/tsl/framework/bfc_allocator.cc:497] *******************************************************************************_____________________\n",
      "2024-12-12 17:06:24.041836: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at cwise_ops_common.h:138 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[750000,2048] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator mklcpu\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "{{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:CPU:0}} OOM when allocating tensor with shape[750000,2048] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator mklcpu [Op:Mul] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Encoder\u001b[39;00m\n\u001b[1;32m      2\u001b[0m inputs \u001b[38;5;241m=\u001b[39m Input(shape\u001b[38;5;241m=\u001b[39m(input_dim,), name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder_input\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m h \u001b[38;5;241m=\u001b[39m \u001b[43mDense\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2048\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrelu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m h \u001b[38;5;241m=\u001b[39m Dense(\u001b[38;5;241m512\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m)(h)\n\u001b[1;32m      5\u001b[0m h \u001b[38;5;241m=\u001b[39m Dense(\u001b[38;5;241m128\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m)(h)\n",
      "File \u001b[0;32m~/miniconda3/envs/josue/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/josue/lib/python3.8/site-packages/keras/src/backend.py:2102\u001b[0m, in \u001b[0;36mRandomGenerator.random_uniform\u001b[0;34m(self, shape, minval, maxval, dtype, nonce)\u001b[0m\n\u001b[1;32m   2100\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nonce:\n\u001b[1;32m   2101\u001b[0m         seed \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mstateless_fold_in(seed, nonce)\n\u001b[0;32m-> 2102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstateless_uniform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2103\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2104\u001b[0m \u001b[43m        \u001b[49m\u001b[43mminval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mminval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2105\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaxval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2106\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2107\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2108\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2109\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform(\n\u001b[1;32m   2110\u001b[0m     shape\u001b[38;5;241m=\u001b[39mshape,\n\u001b[1;32m   2111\u001b[0m     minval\u001b[38;5;241m=\u001b[39mminval,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2114\u001b[0m     seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_legacy_seed(),\n\u001b[1;32m   2115\u001b[0m )\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: {{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:CPU:0}} OOM when allocating tensor with shape[750000,2048] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator mklcpu [Op:Mul] name: "
     ]
    }
   ],
   "source": [
    "# Encoder\n",
    "inputs = Input(shape=(input_dim,), name=\"encoder_input\")\n",
    "h = Dense(2048, activation='relu')(inputs)\n",
    "h = Dense(512, activation='relu')(h)\n",
    "h = Dense(128, activation='relu')(h)\n",
    "\n",
    "z_mean = Dense(latent_dim, name=\"z_mean\")(h)\n",
    "z_log_var = Dense(latent_dim, name=\"z_log_var\")(h)\n",
    "\n",
    "# Sampling function\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim), mean=0., stddev=1.0)\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "z = Lambda(sampling, output_shape=(latent_dim,), name=\"z\")([z_mean, z_log_var])\n",
    "\n",
    "# Decoder\n",
    "latent_inputs = Input(shape=(latent_dim,), name=\"z_sampling\")\n",
    "h_decoded = Dense(128, activation='relu')(latent_inputs)\n",
    "h_decoded = Dense(512, activation='relu')(h_decoded)\n",
    "h_decoded = Dense(2048, activation='relu')(h_decoded)\n",
    "outputs = Dense(input_dim, activation='sigmoid')(h_decoded)\n",
    "\n",
    "# Models\n",
    "encoder = Model(inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "decoder = Model(latent_inputs, outputs, name=\"decoder\")\n",
    "vae_outputs = decoder(encoder(inputs)[2])\n",
    "vae = Model(inputs, vae_outputs, name=\"vae\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322427ae-ac1c-48d8-9f83-25f2d631aff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "reconstruction_loss = MeanSquaredError()(inputs, vae_outputs) * input_dim\n",
    "kl_loss = -0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
    "vae.add_loss(vae_loss)\n",
    "vae.compile(optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131c80a1-9bd7-4ab0-ab05-1245838b6727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the VAE\n",
    "vae.fit(x_train, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c834d5f-79d6-406b-a238-c73775dd16eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling from the latent space\n",
    "def generate_samples(decoder, n_samples=5):\n",
    "    z_samples = np.random.normal(size=(n_samples, latent_dim))\n",
    "    generated = decoder.predict(z_samples)\n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f3f3b6-186f-42ad-85f4-90934c9cd679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate new data\n",
    "new_data = generate_samples(decoder, n_samples=10)\n",
    "print(\"Generated Data:\", new_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
